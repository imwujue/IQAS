{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * 数据准备\n",
    "\n",
    "## * 特征工程\n",
    "#### - 提取字特征\n",
    "#### - 提取词特征\n",
    "#### - 提取图特征\n",
    "## * 模型建立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将txt文件转换为csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = open('./datasets/char_embed.txt')\n",
    "data1 = reader.readlines()\n",
    "with open(\"./datasets/char_embed.csv\",\"w\")as csvfile:\n",
    "    for row in data1:\n",
    "        row = row.split()\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row)\n",
    "        \n",
    "reader = open('./datasets/word_embed.txt')\n",
    "data2 = reader.readlines()\n",
    "with open(\"./datasets/word_embed.csv\",\"w\")as csvfile:\n",
    "    for row in data2:\n",
    "        row = row.split()\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取csv文件，查看内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_master = pd.read_csv('./datasets/train.csv')\n",
    "test_master = pd.read_csv('./datasets/test.csv')\n",
    "question = pd.read_csv('./datasets/question.csv')\n",
    "char_embed = pd.read_csv('./datasets/char_embed.csv',header=None)\n",
    "word_embed = pd.read_csv('./datasets/word_embed.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Q397345</td>\n",
       "      <td>Q538594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Q193805</td>\n",
       "      <td>Q699273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Q085471</td>\n",
       "      <td>Q676160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label       q1       q2\n",
       "0      1  Q397345  Q538594\n",
       "1      0  Q193805  Q699273\n",
       "2      0  Q085471  Q676160"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_master.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q017571</td>\n",
       "      <td>Q006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q728241</td>\n",
       "      <td>Q542572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q166997</td>\n",
       "      <td>Q118270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        q1       q2\n",
       "0  Q017571  Q006012\n",
       "1  Q728241  Q542572\n",
       "2  Q166997  Q118270"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_master.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>words</th>\n",
       "      <th>chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q000000</td>\n",
       "      <td>W05733 W05284 W09158 W14968 W07863</td>\n",
       "      <td>L1128 L1861 L2218 L1796 L1055 L0847 L2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q000001</td>\n",
       "      <td>W17378 W17534 W03249 W01490 W18802</td>\n",
       "      <td>L2214 L1980 L0156 L1554 L2218 L1861 L3019 L010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q000002</td>\n",
       "      <td>W17378 W08158 W20171 W11246 W14759</td>\n",
       "      <td>L2214 L2350 L2568 L1969 L2168 L0694 L3012 L256...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                               words  \\\n",
       "0  Q000000  W05733 W05284 W09158 W14968 W07863   \n",
       "1  Q000001  W17378 W17534 W03249 W01490 W18802   \n",
       "2  Q000002  W17378 W08158 W20171 W11246 W14759   \n",
       "\n",
       "                                               chars  \n",
       "0          L1128 L1861 L2218 L1796 L1055 L0847 L2927  \n",
       "1  L2214 L1980 L0156 L1554 L2218 L1861 L3019 L010...  \n",
       "2  L2214 L2350 L2568 L1969 L2168 L0694 L3012 L256...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L0000</td>\n",
       "      <td>-0.546460</td>\n",
       "      <td>2.285091</td>\n",
       "      <td>-3.084309</td>\n",
       "      <td>1.064661</td>\n",
       "      <td>-2.090880</td>\n",
       "      <td>0.651496</td>\n",
       "      <td>-2.429877</td>\n",
       "      <td>-2.262385</td>\n",
       "      <td>-1.981884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207397</td>\n",
       "      <td>1.476373</td>\n",
       "      <td>0.863744</td>\n",
       "      <td>-0.341826</td>\n",
       "      <td>0.433234</td>\n",
       "      <td>-0.730324</td>\n",
       "      <td>0.215955</td>\n",
       "      <td>-0.528452</td>\n",
       "      <td>-0.340528</td>\n",
       "      <td>-2.018747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0001</td>\n",
       "      <td>-9.016356</td>\n",
       "      <td>-3.801084</td>\n",
       "      <td>-7.210567</td>\n",
       "      <td>3.052900</td>\n",
       "      <td>-1.340958</td>\n",
       "      <td>1.395385</td>\n",
       "      <td>-5.482922</td>\n",
       "      <td>-7.407759</td>\n",
       "      <td>-3.611857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.818142</td>\n",
       "      <td>4.968217</td>\n",
       "      <td>-4.254042</td>\n",
       "      <td>-0.709047</td>\n",
       "      <td>1.288105</td>\n",
       "      <td>-1.222849</td>\n",
       "      <td>-5.521402</td>\n",
       "      <td>-2.653049</td>\n",
       "      <td>1.868731</td>\n",
       "      <td>2.147064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0002</td>\n",
       "      <td>-0.138824</td>\n",
       "      <td>0.219148</td>\n",
       "      <td>-0.890053</td>\n",
       "      <td>0.106301</td>\n",
       "      <td>-0.494364</td>\n",
       "      <td>0.550745</td>\n",
       "      <td>-0.279467</td>\n",
       "      <td>-0.048898</td>\n",
       "      <td>-0.021813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247383</td>\n",
       "      <td>0.576698</td>\n",
       "      <td>1.261507</td>\n",
       "      <td>0.446992</td>\n",
       "      <td>-0.418965</td>\n",
       "      <td>-0.278471</td>\n",
       "      <td>1.426156</td>\n",
       "      <td>-0.579678</td>\n",
       "      <td>-0.322354</td>\n",
       "      <td>-0.661302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6    \\\n",
       "0  L0000 -0.546460  2.285091 -3.084309  1.064661 -2.090880  0.651496   \n",
       "1  L0001 -9.016356 -3.801084 -7.210567  3.052900 -1.340958  1.395385   \n",
       "2  L0002 -0.138824  0.219148 -0.890053  0.106301 -0.494364  0.550745   \n",
       "\n",
       "        7         8         9      ...          291       292       293  \\\n",
       "0 -2.429877 -2.262385 -1.981884    ...     0.207397  1.476373  0.863744   \n",
       "1 -5.482922 -7.407759 -3.611857    ...    -0.818142  4.968217 -4.254042   \n",
       "2 -0.279467 -0.048898 -0.021813    ...     0.247383  0.576698  1.261507   \n",
       "\n",
       "        294       295       296       297       298       299       300  \n",
       "0 -0.341826  0.433234 -0.730324  0.215955 -0.528452 -0.340528 -2.018747  \n",
       "1 -0.709047  1.288105 -1.222849 -5.521402 -2.653049  1.868731  2.147064  \n",
       "2  0.446992 -0.418965 -0.278471  1.426156 -0.579678 -0.322354 -0.661302  \n",
       "\n",
       "[3 rows x 301 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_embed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W00000</td>\n",
       "      <td>0.169316</td>\n",
       "      <td>-0.063898</td>\n",
       "      <td>0.115286</td>\n",
       "      <td>-0.077671</td>\n",
       "      <td>0.067184</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>0.039596</td>\n",
       "      <td>-0.026229</td>\n",
       "      <td>-0.160078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061151</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>-0.194827</td>\n",
       "      <td>0.122456</td>\n",
       "      <td>0.122785</td>\n",
       "      <td>-0.154153</td>\n",
       "      <td>-0.116578</td>\n",
       "      <td>-0.127786</td>\n",
       "      <td>0.110593</td>\n",
       "      <td>-0.171084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W00001</td>\n",
       "      <td>1.548212</td>\n",
       "      <td>-1.052776</td>\n",
       "      <td>1.192632</td>\n",
       "      <td>0.760363</td>\n",
       "      <td>1.594398</td>\n",
       "      <td>1.478917</td>\n",
       "      <td>-1.555349</td>\n",
       "      <td>0.401968</td>\n",
       "      <td>1.588316</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.898932</td>\n",
       "      <td>0.129864</td>\n",
       "      <td>-2.062325</td>\n",
       "      <td>0.068316</td>\n",
       "      <td>0.540282</td>\n",
       "      <td>-1.682620</td>\n",
       "      <td>-0.816290</td>\n",
       "      <td>-1.464458</td>\n",
       "      <td>-0.361792</td>\n",
       "      <td>0.943322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W00002</td>\n",
       "      <td>0.934084</td>\n",
       "      <td>0.106135</td>\n",
       "      <td>-0.391749</td>\n",
       "      <td>-0.209661</td>\n",
       "      <td>-0.558696</td>\n",
       "      <td>-0.942362</td>\n",
       "      <td>-0.274353</td>\n",
       "      <td>-0.232077</td>\n",
       "      <td>-1.024267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.357264</td>\n",
       "      <td>-0.451105</td>\n",
       "      <td>-0.724659</td>\n",
       "      <td>0.525233</td>\n",
       "      <td>0.290343</td>\n",
       "      <td>0.357838</td>\n",
       "      <td>-0.042750</td>\n",
       "      <td>1.315442</td>\n",
       "      <td>-0.167775</td>\n",
       "      <td>-0.393665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6    \\\n",
       "0  W00000  0.169316 -0.063898  0.115286 -0.077671  0.067184  0.019339   \n",
       "1  W00001  1.548212 -1.052776  1.192632  0.760363  1.594398  1.478917   \n",
       "2  W00002  0.934084  0.106135 -0.391749 -0.209661 -0.558696 -0.942362   \n",
       "\n",
       "        7         8         9      ...          291       292       293  \\\n",
       "0  0.039596 -0.026229 -0.160078    ...     0.061151  0.044519 -0.194827   \n",
       "1 -1.555349  0.401968  1.588316    ...    -1.898932  0.129864 -2.062325   \n",
       "2 -0.274353 -0.232077 -1.024267    ...    -0.357264 -0.451105 -0.724659   \n",
       "\n",
       "        294       295       296       297       298       299       300  \n",
       "0  0.122456  0.122785 -0.154153 -0.116578 -0.127786  0.110593 -0.171084  \n",
       "1  0.068316  0.540282 -1.682620 -0.816290 -1.464458 -0.361792  0.943322  \n",
       "2  0.525233  0.290343  0.357838 -0.042750  1.315442 -0.167775 -0.393665  \n",
       "\n",
       "[3 rows x 301 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取train集合字特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_master)\n",
    "train = pd.merge(train, question, left_on = ['q1'], right_on = ['qid'], how = 'left')\n",
    "train = pd.merge(train, question, left_on = ['q2'], right_on = ['qid'], how = 'left')\n",
    "train = train[['label', 'words_x','words_y']]\n",
    "train.columns = ['label', 'q1', 'q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embed.index = word_embed[0]\n",
    "word = word_embed.index.values\n",
    "word_to_index = dict([(word[i],i) for i in range(len(word))])\n",
    "index_to_word = dict([(i, word[i]) for i in range(len(word))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q1 = train.q1.values\n",
    "train_q2 = train.q2.values\n",
    "train_shape_q1 = train_q1.shape[0]\n",
    "train_shape_q2 = train_q2.shape[0]\n",
    "max_len = 20\n",
    "embed_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q1_indices = np.zeros((train_shape_q1,max_len))\n",
    "for i in range(train_shape_q1):\n",
    "    sentence_words_q1 = train_q1[i].split(' ')\n",
    "    for j,w in enumerate(sentence_words_q1):\n",
    "        if j >= max_len:\n",
    "            break\n",
    "        train_q1_indices[i, j] = word_to_index[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q2_indices = np.zeros((train_shape_q2,max_len))\n",
    "for i in range(train_shape_q2):\n",
    "    sentence_words_q2 = train_q2[i].split(' ')\n",
    "    for j,w in enumerate(sentence_words_q2):\n",
    "        if j >= max_len:\n",
    "            break\n",
    "        train_q2_indices[i, j] = word_to_index[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算q1，q2长度差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.28571429 ... 0.14285714 0.3        0.5       ]\n"
     ]
    }
   ],
   "source": [
    "merge = train[['q1', 'q2']]\n",
    "q1_len = merge.q1.apply(lambda x: len(x.split(' '))).values\n",
    "q2_len = merge.q2.apply(lambda x: len(x.split(' '))).values\n",
    "len_diff = np.abs((q1_len - q2_len))/np.max([q1_len, q2_len], axis=0)\n",
    "# print(len_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算q1，q2中相同的字的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_word_set = merge.q1.apply(lambda x: x.split(' ')).apply(set).values\n",
    "q2_word_set = merge.q2.apply(lambda x: x.split(' ')).apply(set).values\n",
    "result = [len(q1_word_set[i] & q2_word_set[i]) for i in range(max(len(q1_word_set), len(q2_word_set)))]\n",
    "result = pd.DataFrame(result)\n",
    "result.columns = ['num_common_words']\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算共现字比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = [len(q1_word_set[i] & q2_word_set[i])/max(q1_len[i], q2_len[i]) for i in range(len(q1_word_set))]\n",
    "ratio = pd.DataFrame(ratio)\n",
    "result.columns = ['common_word_ratio']\n",
    "# print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算tf-idf字向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(merge.q2.values)\n",
    "sorted(merge.q2.values)\n",
    "vectorizer = TfidfVectorizer().fit(question.words.values)\n",
    "q1_tfidf = vectorizer.transform(merge.q1.values)\n",
    "q2_tfidf = vectorizer.transform(merge.q2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据tf-idf系数调整共现字比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_common_word_ratio = []\n",
    "for i in range(0,q1_tfidf.shape[0]):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in merge.loc[i, 'q1'].split():\n",
    "        q1words[word] = q1words.get(word,0)+1\n",
    "#         print(q1words[word])\n",
    "    for word in merge.loc[i, 'q2'].split():\n",
    "        q2words[word] = q2words.get(word,0)+1\n",
    "#         print(q2words[word])\n",
    "    sum_shared_word_in_q1 = sum([q1words[w] * q1_tfidf[i,word_to_index[w]] for w in q1words if w in q2words])\n",
    "#     print(sum_shared_word_in_q1)\n",
    "    sum_shared_word_in_q2 = sum([q2words[w] * q2_tfidf[i,word_to_index[w]] for w in q2words if w in q1words])\n",
    "#     print(sum_shared_word_in_q2)\n",
    "    sum1 = sum(q1words[w] * q1_tfidf[i,word_to_index[w]] for w in q1words if word_to_index[w] != 20890) \n",
    "    sum2 = sum(q2words[w] * q2_tfidf[i,word_to_index[w]] for w in q2words)\n",
    "    sum_tol = sum1 + sum2\n",
    "#     print(sum_tol)\n",
    "    if sum_tol<1e-6:\n",
    "        adjusted_common_word_ratio.append(0.0)\n",
    "    else:\n",
    "#         print(sum_shared_word_in_q1)\n",
    "#         print(sum_shared_word_in_q2)\n",
    "#         print(sum_tol)\n",
    "#         print()\n",
    "        adjusted_common_word_ratio.append(1.0 * (sum_shared_word_in_q1 + sum_shared_word_in_q2)/sum_tol)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算字影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_power = {}\n",
    "for i in train.index:\n",
    "    label = int(train.loc[i, 'label'])\n",
    "    q1_words = train.loc[i, 'q1'].lower().split()\n",
    "    q2_words = train.loc[i, 'q2'].lower().split()\n",
    "    all_words = set(q1_words + q2_words)\n",
    "    q1_words = set(q1_words)\n",
    "    q2_words = set(q2_words)\n",
    "    for word in all_words:\n",
    "        if word not in words_power:\n",
    "            words_power[word] = [0. for i in range(7)]\n",
    "        words_power[word][0] += 1.            \n",
    "        words_power[word][1] += 1.\n",
    "        if ((word in q1_words) and (word not in q2_words)) or ((word not in q1_words) and (word in q2_words)):\n",
    "            words_power[word][3] += 1.\n",
    "            if label == 0:\n",
    "                words_power[word][2] += 1.\n",
    "                words_power[word][4] += 1.\n",
    "        if (word in q1_words) and (word in q2_words):\n",
    "            words_power[word][5] += 1.\n",
    "            if label == 1:\n",
    "                words_power[word][2] += 1.\n",
    "                words_power[word][6] += 1.\n",
    "for word in words_power:\n",
    "    words_power[word][1]  /= train.shape[0]\n",
    "    words_power[word][2] /= words_power[word][0]\n",
    "    if words_power[word][3] > 1e-6:\n",
    "        words_power[word][4] /= words_power[word][3]        \n",
    "    words_power[word][5] /= words_power[word][0]\n",
    "sorted_words_power = sorted(words_power.items(), key =lambda d: d[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测有双侧影响力的字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_num, thresh_rate = 7, 0.3\n",
    "pword_dside = []\n",
    "pword = sorted_words_power\n",
    "pword = filter(lambda x: x[1][0] * x[1][5] >=thresh_num , pword)\n",
    "pword_sort = sorted(pword, key = lambda d: d[1][6], reverse = True)\n",
    "pword_dside.extend(map(lambda x: x[0], filter(lambda x: x[1][6]>=thresh_rate, pword_sort)))\n",
    "merge = train[['q1', 'q2']]\n",
    "pword_dside_tags = []\n",
    "for i in merge.index:\n",
    "    tags = []\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    for word in pword_dside:\n",
    "        if (word in q1_words) and (word in q2_words):\n",
    "            tags.append(1.0)\n",
    "        else:\n",
    "            tags.append(0.0)\n",
    "    pword_dside_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测有单侧影响力的字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_num, thresh_rate = 7, 0.3\n",
    "pword_oside = []\n",
    "pword = sorted_words_power\n",
    "pword = filter(lambda x: x[1][0] * x[1][5] >=thresh_num , pword)\n",
    "pword_oside.extend(map(lambda x: x[0], filter(lambda x: x[1][4]>thresh_rate, pword)))\n",
    "merge = train[['q1', 'q2']]\n",
    "pword_oside_tags = []\n",
    "for i in merge.index:\n",
    "    tags = []\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    for word in pword_oside:\n",
    "        if (word in q1_words) and (word not in q2_words):\n",
    "            tags.append(1.0)\n",
    "        else:\n",
    "            tags.append(0.0)\n",
    "    pword_oside_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算单字的双侧影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_least = 300\n",
    "merge = train[['q1', 'q2']]\n",
    "words_power = dict(sorted_words_power)\n",
    "pword_dside_rate = []\n",
    "for i in merge.index:\n",
    "    rate = 1.0\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    share_words = list(q1_words.intersection(q2_words))\n",
    "    for word in share_words:\n",
    "        if word in pword_dside:\n",
    "            rate *= (1.0 - words_power[word][6])\n",
    "    pword_dside_rate.append(1-rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算单字的单侧影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_least = 300\n",
    "merge = train[['q1', 'q2']]\n",
    "words_power = dict(sorted_words_power)\n",
    "pword_oside_rate = []\n",
    "for i in merge.index:\n",
    "    rate = 1.0\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    q1_diff = list(set(q1_words).difference(set(q2_words)))\n",
    "    q2_diff = list(set(q2_words).difference(set(q1_words)))\n",
    "    all_diff = set(q1_diff + q2_diff)\n",
    "    for word in all_diff:\n",
    "        if word in pword_oside:\n",
    "            rate *= (1.0-words_power[word][4])\n",
    "    pword_oside_rate.append(1-rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算可编辑距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(q1, q2):\n",
    "    str1 = q1.split(' ')\n",
    "    str2 = q2.split(' ')\n",
    "    matrix = [[i+j for j in range(len(str2)+1)] for i in range(len(str1)+1)]\n",
    "    for i in range(1, len(str1)+1):\n",
    "        for j in range(1, len(str2)+1):\n",
    "            if str1[i-1] == str2[j-1]:\n",
    "                d = 0\n",
    "            else:\n",
    "                d = 1\n",
    "            matrix[i][j] = min(matrix[i-1][j]+1, matrix[i][j-1]+1, matrix[i-1][j-1]+d)\n",
    "        if i>1 and j >1 and str1[i-1] == str2[j-2] and str1[i-2] == str2[j-1]:\n",
    "            d = 0\n",
    "            matrix[i][j] = min(matrix[i][j], matrix[i-2][j-2]+d)\n",
    "    return matrix[len(str1)][len(str2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_len = merge['q1'].apply(lambda x: len(x.split(' '))).values\n",
    "q2_len = merge['q2'].apply(lambda x: len(x.split(' '))).values\n",
    "dist =[edit_distance(merge.loc[i,'q1'],merge.loc[i,'q2'])/np.max([q1_len,q2_len],axis=0)[i] for i in merge.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并提取的字特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_common_word_ratio = pd.DataFrame(adjusted_common_word_ratio)\n",
    "edit_distance = pd.DataFrame(dist)\n",
    "len_diff = pd.DataFrame(len_diff)\n",
    "pword_dside_rate = pd.DataFrame(pword_dside_rate)\n",
    "pword_oside_rate = pd.DataFrame(pword_oside_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.merge(adjusted_common_word_ratio, edit_distance, left_index = True,right_index =  True)\n",
    "train_features = pd.merge(train_features, len_diff, left_index = True,right_index =  True)\n",
    "train_features = pd.merge(train_features, pword_dside_rate, left_index = True,right_index =  True)\n",
    "train_features = pd.merge(train_features, pword_oside_rate, left_index = True,right_index =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.columns = ['adjusted_common_word_ratio','edit_distance','len_diff','pword_dside_rate','pword_oside_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv('output/train_feature_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, merge, adjusted_common_word_ratio, edit_distance, len_diff, pword_dside_rate, pword_oside_rate\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取词特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_master)\n",
    "train = pd.merge(train, question, left_on = ['q1'], right_on = ['qid'], how = 'left')\n",
    "train = pd.merge(train, question, left_on = ['q2'], right_on = ['qid'], how = 'left')\n",
    "train = train[['label', 'chars_x','chars_y']]\n",
    "train.columns = ['label', 'q1', 'q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed.index = char_embed[0]\n",
    "char = char_embed.index.values\n",
    "char_to_index = dict([(char[i],i) for i in range(len(char))])\n",
    "index_to_char = dict([(i, char[i]) for i in range(len(char))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q1 = train.q1.values\n",
    "train_q2 = train.q2.values\n",
    "train_shape_q1 = train_q1.shape[0]\n",
    "train_shape_q2 = train_q2.shape[0]\n",
    "max_len = 20\n",
    "embed_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q1_indices = np.zeros((train_shape_q1,max_len))\n",
    "for i in range(train_shape_q1):\n",
    "    sentence_chars_q1 = train_q1[i].split(' ')\n",
    "    for j,w in enumerate(sentence_chars_q1):\n",
    "        if j >= max_len:\n",
    "            break\n",
    "        train_q1_indices[i, j] = char_to_index[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_q2_indices = np.zeros((train_shape_q1,max_len))\n",
    "for i in range(train_shape_q2):\n",
    "    sentence_chars_q1 = train_q2[i].split(' ')\n",
    "    for j,w in enumerate(sentence_chars_q1):\n",
    "        if j >= max_len:\n",
    "            break\n",
    "        train_q2_indices[i, j] = char_to_index[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算q1，q2长度差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = train[['q1', 'q2']]\n",
    "q1_len = merge.q1.apply(lambda x: len(x.split(' '))).values\n",
    "q2_len = merge.q2.apply(lambda x: len(x.split(' '))).values\n",
    "len_diff = np.abs((q1_len - q2_len))/np.max([q1_len, q2_len], axis=0)\n",
    "# print(len_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算q1，q2中相同的词的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_word_set = merge.q1.apply(lambda x: x.split(' ')).apply(set).values\n",
    "q2_word_set = merge.q2.apply(lambda x: x.split(' ')).apply(set).values\n",
    "result = [len(q1_word_set[i] & q2_word_set[i]) for i in range(max(len(q1_word_set), len(q2_word_set)))]\n",
    "result = pd.DataFrame(result)\n",
    "result.columns = ['num_common_words']\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算共现词比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = [len(q1_word_set[i] & q2_word_set[i])/max(q1_len[i], q2_len[i]) for i in range(len(q1_word_set))]\n",
    "ratio = pd.DataFrame(ratio)\n",
    "result.columns = ['common_word_ratio']\n",
    "# print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算tf-idf词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(merge.q2.values)\n",
    "sorted(merge.q2.values)\n",
    "vectorizer = TfidfVectorizer().fit(question.words.values)\n",
    "q1_tfidf = vectorizer.transform(merge.q1.values)\n",
    "q2_tfidf = vectorizer.transform(merge.q2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据tf-idf系数调整共现词比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_common_word_ratio = []\n",
    "for i in range(0,q1_tfidf.shape[0]):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in merge.loc[i, 'q1'].split():\n",
    "        q1words[word] = q1words.get(word,0)+1\n",
    "    for word in merge.loc[i, 'q2'].split():\n",
    "        q2words[word] = q2words.get(word,0)+1\n",
    "    sum_shared_word_in_q1 = sum([q1words[w] * q1_tfidf[i, char_to_index[w]] for w in q1words if w in q2words])\n",
    "    sum_shared_word_in_q2 = sum([q2words[w] * q2_tfidf[i,char_to_index[w]] for w in q2words if w in q1words])\n",
    "    sum1 = sum(q1words[w] * q1_tfidf[i,char_to_index[w]] for w in q1words) \n",
    "    sum2 = sum(q2words[w] * q2_tfidf[i,char_to_index[w]] for w in q2words)\n",
    "    sum_tol = sum1 + sum2\n",
    "    if sum_tol<1e-6:\n",
    "        adjusted_common_word_ratio.append(0.0)\n",
    "    else:\n",
    "        adjusted_common_word_ratio.append(1.0 * (sum_shared_word_in_q1 + sum_shared_word_in_q2)/sum_tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算词影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_power = {}\n",
    "for i in train.index:\n",
    "    label = int(train.loc[i, 'label'])\n",
    "    q1_words = train.loc[i, 'q1'].lower().split()\n",
    "    q2_words = train.loc[i, 'q2'].lower().split()\n",
    "    all_words = set(q1_words + q2_words)\n",
    "    q1_words = set(q1_words)\n",
    "    q2_words = set(q2_words)\n",
    "    for word in all_words:\n",
    "        if word not in words_power:\n",
    "            words_power[word] = [0. for i in range(7)]\n",
    "        words_power[word][0] += 1.            \n",
    "        words_power[word][1] += 1.\n",
    "        if ((word in q1_words) and (word not in q2_words)) or ((word not in q1_words) and (word in q2_words)):\n",
    "            words_power[word][3] += 1.\n",
    "            if label == 0:\n",
    "                words_power[word][2] += 1.\n",
    "                words_power[word][4] += 1.\n",
    "        if (word in q1_words) and (word in q2_words):\n",
    "            words_power[word][5] += 1.\n",
    "            if label == 1:\n",
    "                words_power[word][2] += 1.\n",
    "                words_power[word][6] += 1.\n",
    "for word in words_power:\n",
    "    words_power[word][1]  /= train.shape[0]\n",
    "    words_power[word][2] /= words_power[word][0]\n",
    "    if words_power[word][3] > 1e-6:\n",
    "        words_power[word][4] /= words_power[word][3]        \n",
    "    words_power[word][5] /= words_power[word][0]\n",
    "sorted_words_power = sorted(words_power.items(), key =lambda d: d[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测有双侧影响力的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_num, thresh_rate = 7, 0.3\n",
    "pword_dside = []\n",
    "pword = sorted_words_power\n",
    "pword = filter(lambda x: x[1][0] * x[1][5] >=thresh_num , pword)\n",
    "pword_sort = sorted(pword, key = lambda d: d[1][6], reverse = True)\n",
    "pword_dside.extend(map(lambda x: x[0], filter(lambda x: x[1][6]>=thresh_rate, pword_sort)))\n",
    "merge = train[['q1', 'q2']]\n",
    "pword_dside_tags = []\n",
    "for i in merge.index:\n",
    "    tags = []\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    for word in pword_dside:\n",
    "        if (word in q1_words) and (word in q2_words):\n",
    "            tags.append(1.0)\n",
    "        else:\n",
    "            tags.append(0.0)\n",
    "    pword_dside_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测有单侧影响力的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_num, thresh_rate = 7, 0.3\n",
    "pword_oside = []\n",
    "pword = sorted_words_power\n",
    "pword = filter(lambda x: x[1][0] * x[1][5] >=thresh_num , pword)\n",
    "pword_oside.extend(map(lambda x: x[0], filter(lambda x: x[1][4]>thresh_rate, pword)))\n",
    "merge = train[['q1', 'q2']]\n",
    "pword_oside_tags = []\n",
    "for i in merge.index:\n",
    "    tags = []\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    for word in pword_oside:\n",
    "        if (word in q1_words) and (word not in q2_words):\n",
    "            tags.append(1.0)\n",
    "        else:\n",
    "            tags.append(0.0)\n",
    "    pword_oside_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算词的双侧影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_least = 300\n",
    "merge = train[['q1', 'q2']]\n",
    "words_power = dict(sorted_words_power)\n",
    "pword_dside_rate = []\n",
    "for i in merge.index:\n",
    "    rate = 1.0\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    share_words = list(q1_words.intersection(q2_words))\n",
    "    for word in share_words:\n",
    "        if word in pword_dside:\n",
    "            rate *= (1.0 - words_power[word][6])\n",
    "    pword_dside_rate.append(1-rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测词的单侧影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_least = 300\n",
    "merge = train[['q1', 'q2']]\n",
    "words_power = dict(sorted_words_power)\n",
    "pword_oside_rate = []\n",
    "for i in merge.index:\n",
    "    rate = 1.0\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    q1_diff = list(set(q1_words).difference(set(q2_words)))\n",
    "    q2_diff = list(set(q2_words).difference(set(q1_words)))\n",
    "    all_diff = set(q1_diff + q2_diff)\n",
    "    for word in all_diff:\n",
    "        if word in pword_oside:\n",
    "            rate *= (1.0-words_power[word][4])\n",
    "    pword_oside_rate.append(1-rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并提取的词特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_common_char_ratio = pd.DataFrame(adjusted_common_word_ratio)\n",
    "pchar_dside_rate = pd.DataFrame(pword_dside_rate)\n",
    "pchar_oside_rate = pd.DataFrame(pword_oside_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('output/train_feature_words.csv', index_col=0)\n",
    "train_features = pd.DataFrame(train_features)\n",
    "train_features = pd.merge(train_features, adjusted_common_char_ratio, left_index = True,right_index =  True)\n",
    "train_features = pd.merge(train_features, pchar_dside_rate, left_index = True,right_index =  True)\n",
    "train_features = pd.merge(train_features, pchar_oside_rate, left_index = True,right_index =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.columns = ['adjusted_common_word_ratio','edit_distance','len_diff',\n",
    "                          'pword_dside_rate','pword_oside_rate','adjusted_common_char_ratio','pchar_dside_rate','pchar_oside_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv('output/train_feature.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取test集合字特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_master)\n",
    "test = pd.merge(test, question, left_on = ['q1'], right_on = ['qid'], how = 'left')\n",
    "test = pd.merge(test, question, left_on = ['q2'], right_on = ['qid'], how = 'left')\n",
    "test = test[['words_x','words_y']]\n",
    "test.columns = ['q1', 'q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q1 = test.q1.values\n",
    "test_q2 = test.q2.values\n",
    "test_shape_q1 = test_q1.shape[0]\n",
    "test_shape_q2 = test_q2.shape[0]\n",
    "max_len = 20\n",
    "embed_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embed.index = word_embed[0]\n",
    "word = word_embed.index.values\n",
    "word_to_index = dict([(word[i],i) for i in range(len(word))])\n",
    "index_to_word = dict([(i, word[i]) for i in range(len(word))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q1_indices = np.zeros((test_shape_q1,max_len))\n",
    "for i in range(test_shape_q1):\n",
    "    sentence_words_q1 = test_q1[i].split(' ')\n",
    "    for j,w in enumerate(sentence_words_q1):\n",
    "        if j >= max_len:\n",
    "            break\n",
    "        test_q1_indices[i, j] = word_to_index[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q2_indices = np.zeros((test_shape_q2,max_len))\n",
    "for i in range(test_shape_q2):\n",
    "    sentence_words_q2 = test_q2[i].split(' ')\n",
    "    for j,w in enumerate(sentence_words_q2):\n",
    "        if j >= max_len:\n",
    "            break\n",
    "        test_q2_indices[i, j] = word_to_index[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算q1，q2长度差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = test[['q1', 'q2']]\n",
    "q1_len = merge.q1.apply(lambda x: len(x.split(' '))).values\n",
    "q2_len = merge.q2.apply(lambda x: len(x.split(' '))).values\n",
    "len_diff = np.abs((q1_len - q2_len))/np.max([q1_len, q2_len], axis=0)\n",
    "# print(len_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算q1，q2中相同的字的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_word_set = merge.q1.apply(lambda x: x.split(' ')).apply(set).values\n",
    "q2_word_set = merge.q2.apply(lambda x: x.split(' ')).apply(set).values\n",
    "result = [len(q1_word_set[i] & q2_word_set[i]) for i in range(max(len(q1_word_set), len(q2_word_set)))]\n",
    "result = pd.DataFrame(result)\n",
    "result.columns = ['num_common_words']\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算共现字比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = [len(q1_word_set[i] & q2_word_set[i])/max(q1_len[i], q2_len[i]) for i in range(len(q1_word_set))]\n",
    "ratio = pd.DataFrame(ratio)\n",
    "result.columns = ['common_word_ratio']\n",
    "# print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算tfi-df字向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(merge.q2.values)\n",
    "sorted(merge.q2.values)\n",
    "vectorizer = TfidfVectorizer().fit(question.words.values)\n",
    "q1_tfidf = vectorizer.transform(merge.q1.values)\n",
    "q2_tfidf = vectorizer.transform(merge.q2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据tf-idf系数调整共现词比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_common_word_ratio = []\n",
    "count =0\n",
    "for i in range(0,q1_tfidf.shape[0]):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in merge.loc[i, 'q1'].split():\n",
    "        q1words[word] = q1words.get(word,0)+1\n",
    "    for word in merge.loc[i, 'q2'].split():\n",
    "        q2words[word] = q2words.get(word,0)+1\n",
    "    sum_shared_word_in_q1 = sum([q1words[w] * q1_tfidf[i,word_to_index[w]] for w in q1words if w in q2words])\n",
    "    sum_shared_word_in_q2 = sum([q2words[w] * q2_tfidf[i,word_to_index[w]] for w in q2words if w in q1words])\n",
    "    sum1 = sum(q1words[w] * q1_tfidf[i,word_to_index[w]] for w in q1words) \n",
    "    sum2 = sum(q2words[w] * q2_tfidf[i,word_to_index[w]] for w in q2words)\n",
    "    sum_tol = sum1 + sum2\n",
    "    if sum_tol<1e-6:\n",
    "        adjusted_common_word_ratio.append(0.0)\n",
    "    else:\n",
    "        adjusted_common_word_ratio.append(1.0 * (sum_shared_word_in_q1 + sum_shared_word_in_q2)/sum_tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算字影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_power = {}\n",
    "for i in train.index:\n",
    "    label = int(train.loc[i, 'label'])\n",
    "    q1_words = train.loc[i, 'q1'].lower().split()\n",
    "    q2_words = train.loc[i, 'q2'].lower().split()\n",
    "    all_words = set(q1_words + q2_words)\n",
    "    q1_words = set(q1_words)\n",
    "    q2_words = set(q2_words)\n",
    "    for word in all_words:\n",
    "        if word not in words_power:\n",
    "            words_power[word] = [0. for i in range(7)]\n",
    "        words_power[word][0] += 1.            \n",
    "        words_power[word][1] += 1.\n",
    "        if ((word in q1_words) and (word not in q2_words)) or ((word not in q1_words) and (word in q2_words)):\n",
    "            words_power[word][3] += 1.\n",
    "            if label == 0:\n",
    "                words_power[word][2] += 1.\n",
    "                words_power[word][4] += 1.\n",
    "        if (word in q1_words) and (word in q2_words):\n",
    "            words_power[word][5] += 1.\n",
    "            if label == 1:\n",
    "                words_power[word][2] += 1.\n",
    "                words_power[word][6] += 1.\n",
    "for word in words_power:\n",
    "    words_power[word][1]  /= train.shape[0]\n",
    "    words_power[word][2] /= words_power[word][0]\n",
    "    if words_power[word][3] > 1e-6:\n",
    "        words_power[word][4] /= words_power[word][3]        \n",
    "    words_power[word][5] /= words_power[word][0]\n",
    "sorted_words_power = sorted(words_power.items(), key =lambda d: d[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测具有双侧影响力的字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_num, thresh_rate = 7, 0.3\n",
    "pword_dside = []\n",
    "pword = sorted_words_power\n",
    "pword = filter(lambda x: x[1][0] * x[1][5] >=thresh_num , pword)\n",
    "pword_sort = sorted(pword, key = lambda d: d[1][6], reverse = True)\n",
    "pword_dside.extend(map(lambda x: x[0], filter(lambda x: x[1][6]>=thresh_rate, pword_sort)))\n",
    "merge = train[['q1', 'q2']]\n",
    "pword_dside_tags = []\n",
    "for i in merge.index:\n",
    "    tags = []\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    for word in pword_dside:\n",
    "        if (word in q1_words) and (word in q2_words):\n",
    "            tags.append(1.0)\n",
    "        else:\n",
    "            tags.append(0.0)\n",
    "    pword_dside_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测具有单侧影响力的字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_num, thresh_rate = 7, 0.3\n",
    "pword_oside = []\n",
    "pword = sorted_words_power\n",
    "pword = filter(lambda x: x[1][0] * x[1][5] >=thresh_num , pword)\n",
    "pword_oside.extend(map(lambda x: x[0], filter(lambda x: x[1][4]>thresh_rate, pword)))\n",
    "merge = train[['q1', 'q2']]\n",
    "pword_oside_tags = []\n",
    "for i in merge.index:\n",
    "    tags = []\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    for word in pword_oside:\n",
    "        if (word in q1_words) and (word not in q2_words):\n",
    "            tags.append(1.0)\n",
    "        else:\n",
    "            tags.append(0.0)\n",
    "    pword_oside_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算字的双侧影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_least = 300\n",
    "merge = train[['q1', 'q2']]\n",
    "words_power = dict(sorted_words_power)\n",
    "pword_dside_rate = []\n",
    "for i in merge.index:\n",
    "    rate = 1.0\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    share_words = list(q1_words.intersection(q2_words))\n",
    "    for word in share_words:\n",
    "        if word in pword_dside:\n",
    "            rate *= (1.0 - words_power[word][6])\n",
    "    pword_dside_rate.append(1-rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算字的单侧影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_least = 300\n",
    "merge = train[['q1', 'q2']]\n",
    "words_power = dict(sorted_words_power)\n",
    "pword_oside_rate = []\n",
    "for i in merge.index:\n",
    "    rate = 1.0\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    q1_diff = list(set(q1_words).difference(set(q2_words)))\n",
    "    q2_diff = list(set(q2_words).difference(set(q1_words)))\n",
    "    all_diff = set(q1_diff + q2_diff)\n",
    "    for word in all_diff:\n",
    "        if word in pword_oside:\n",
    "            rate *= (1.0-words_power[word][4])\n",
    "    pword_oside_rate.append(1-rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算可编辑距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(q1, q2):\n",
    "    str1 = q1.split(' ')\n",
    "    str2 = q2.split(' ')\n",
    "    matrix = [[i+j for j in range(len(str2)+1)] for i in range(len(str1)+1)]\n",
    "    for i in range(1, len(str1)+1):\n",
    "        for j in range(1, len(str2)+1):\n",
    "            if str1[i-1] == str2[j-1]:\n",
    "                d = 0\n",
    "            else:\n",
    "                d = 1\n",
    "            matrix[i][j] = min(matrix[i-1][j]+1, matrix[i][j-1]+1, matrix[i-1][j-1]+d)\n",
    "        if i>1 and j >1 and str1[i-1] == str2[j-2] and str1[i-2] == str2[j-1]:\n",
    "            d = 0\n",
    "            matrix[i][j] = min(matrix[i][j], matrix[i-2][j-2]+d)\n",
    "    return matrix[len(str1)][len(str2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_len = merge['q1'].apply(lambda x: len(x.split(' '))).values\n",
    "q2_len = merge['q2'].apply(lambda x: len(x.split(' '))).values\n",
    "dist =[edit_distance(merge.loc[i,'q1'],merge.loc[i,'q2'])/np.max([q1_len,q2_len],axis=0)[i] for i in merge.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并提取的字特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_common_word_ratio = pd.DataFrame(adjusted_common_word_ratio)\n",
    "edit_distance = pd.DataFrame(dist)\n",
    "len_diff = pd.DataFrame(len_diff)\n",
    "pword_dside_rate = pd.DataFrame(pword_dside_rate)\n",
    "pword_oside_rate = pd.DataFrame(pword_oside_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.merge(adjusted_common_word_ratio, edit_distance, left_index = True,right_index =  True)\n",
    "test_features = pd.merge(test_features, len_diff, left_index = True,right_index =  True)\n",
    "test_features = pd.merge(test_features, pword_dside_rate, left_index = True,right_index =  True)\n",
    "test_features = pd.merge(test_features, pword_oside_rate, left_index = True,right_index =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.columns = ['adjusted_common_word_ratio','edit_distance','len_diff','pword_dside_rate','pword_oside_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.to_csv('output/test_feature_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取test集合字特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(test_master)\n",
    "test = pd.merge(test, question, left_on = ['q1'], right_on = ['qid'], how = 'left')\n",
    "test = pd.merge(test, question, left_on = ['q2'], right_on = ['qid'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['chars_x','chars_y']]\n",
    "test.columns = ['q1', 'q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q1 = test.q1.values\n",
    "test_q2 = test.q2.values\n",
    "test_shape_q1 = test_q1.shape[0]\n",
    "test_shape_q2 = test_q2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q1_indices = np.zeros((test_shape_q1,max_len))\n",
    "for i in range(test_shape_q1):\n",
    "    sentence_chars_q1 = test_q1[i].split(' ')\n",
    "    for j,w in enumerate(sentence_chars_q1):\n",
    "        if j >= max_len:\n",
    "            break\n",
    "        test_q1_indices[i, j] = char_to_index[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q2_indices = np.zeros((test_shape_q2,max_len))\n",
    "for i in range(test_shape_q1):\n",
    "    sentence_chars_q2 = test_q2[i].split(' ')\n",
    "    for j,w in enumerate(sentence_chars_q1):\n",
    "        if j >= max_len:\n",
    "            break\n",
    "        test_q2_indices[i, j] = char_to_index[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算q1，q2长度差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = test[['q1', 'q2']]\n",
    "q1_len = merge.q1.apply(lambda x: len(x.split(' '))).values\n",
    "q2_len = merge.q2.apply(lambda x: len(x.split(' '))).values\n",
    "len_diff = np.abs((q1_len - q2_len))/np.max([q1_len, q2_len], axis=0)\n",
    "# print(len_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算q1，q2中相同的词的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_word_set = merge.q1.apply(lambda x: x.split(' ')).apply(set).values\n",
    "q2_word_set = merge.q2.apply(lambda x: x.split(' ')).apply(set).values\n",
    "result = [len(q1_word_set[i] & q2_word_set[i]) for i in range(max(len(q1_word_set), len(q2_word_set)))]\n",
    "result = pd.DataFrame(result)\n",
    "result.columns = ['num_common_words']\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算共现词比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = [len(q1_word_set[i] & q2_word_set[i])/max(q1_len[i], q2_len[i]) for i in range(len(q1_word_set))]\n",
    "ratio = pd.DataFrame(ratio)\n",
    "result.columns = ['common_word_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算tf-idf词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(merge.q2.values)\n",
    "sorted(merge.q2.values)\n",
    "vectorizer = TfidfVectorizer().fit(question.words.values)\n",
    "q1_tfidf = vectorizer.transform(merge.q1.values)\n",
    "q2_tfidf = vectorizer.transform(merge.q2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据tf-idf系数调整共现词比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_common_word_ratio = []\n",
    "for i in range(0,q1_tfidf.shape[0]):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in merge.loc[i, 'q1'].split():\n",
    "        q1words[word] = q1words.get(word,0)+1\n",
    "    for word in merge.loc[i, 'q2'].split():\n",
    "        q2words[word] = q2words.get(word,0)+1\n",
    "    sum_shared_word_in_q1 = sum([q1words[w] * q1_tfidf[i, char_to_index[w]] for w in q1words if w in q2words])\n",
    "    sum_shared_word_in_q2 = sum([q2words[w] * q2_tfidf[i,char_to_index[w]] for w in q2words if w in q1words])\n",
    "    sum1 = sum(q1words[w] * q1_tfidf[i,char_to_index[w]] for w in q1words) \n",
    "    sum2 = sum(q2words[w] * q2_tfidf[i,char_to_index[w]] for w in q2words)\n",
    "    sum_tol = sum1 + sum2\n",
    "    if sum_tol<1e-6:\n",
    "        adjusted_common_word_ratio.append(0.0)\n",
    "    else:\n",
    "        adjusted_common_word_ratio.append(1.0 * (sum_shared_word_in_q1 + sum_shared_word_in_q2)/sum_tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算词影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_power = {}\n",
    "for i in train.index:\n",
    "    label = int(train.loc[i, 'label'])\n",
    "    q1_words = train.loc[i, 'q1'].lower().split()\n",
    "    q2_words = train.loc[i, 'q2'].lower().split()\n",
    "    all_words = set(q1_words + q2_words)\n",
    "    q1_words = set(q1_words)\n",
    "    q2_words = set(q2_words)\n",
    "    for word in all_words:\n",
    "        if word not in words_power:\n",
    "            words_power[word] = [0. for i in range(7)]\n",
    "        words_power[word][0] += 1.            \n",
    "        words_power[word][1] += 1.\n",
    "        if ((word in q1_words) and (word not in q2_words)) or ((word not in q1_words) and (word in q2_words)):\n",
    "            words_power[word][3] += 1.\n",
    "            if label == 0:\n",
    "                words_power[word][2] += 1.\n",
    "                words_power[word][4] += 1.\n",
    "        if (word in q1_words) and (word in q2_words):\n",
    "            words_power[word][5] += 1.\n",
    "            if label == 1:\n",
    "                words_power[word][2] += 1.\n",
    "                words_power[word][6] += 1.\n",
    "for word in words_power:\n",
    "    words_power[word][1]  /= train.shape[0]\n",
    "    words_power[word][2] /= words_power[word][0]\n",
    "    if words_power[word][3] > 1e-6:\n",
    "        words_power[word][4] /= words_power[word][3]        \n",
    "    words_power[word][5] /= words_power[word][0]\n",
    "sorted_words_power = sorted(words_power.items(), key =lambda d: d[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测具有双侧影响力的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_num, thresh_rate = 7, 0.3\n",
    "pword_dside = []\n",
    "pword = sorted_words_power\n",
    "pword = filter(lambda x: x[1][0] * x[1][5] >=thresh_num , pword)\n",
    "pword_sort = sorted(pword, key = lambda d: d[1][6], reverse = True)\n",
    "pword_dside.extend(map(lambda x: x[0], filter(lambda x: x[1][6]>=thresh_rate, pword_sort)))\n",
    "merge = train[['q1', 'q2']]\n",
    "pword_dside_tags = []\n",
    "for i in merge.index:\n",
    "    tags = []\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    for word in pword_dside:\n",
    "        if (word in q1_words) and (word in q2_words):\n",
    "            tags.append(1.0)\n",
    "        else:\n",
    "            tags.append(0.0)\n",
    "    pword_dside_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测具有单侧影响力的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_num, thresh_rate = 7, 0.3\n",
    "pword_oside = []\n",
    "pword = sorted_words_power\n",
    "pword = filter(lambda x: x[1][0] * x[1][5] >=thresh_num , pword)\n",
    "pword_oside.extend(map(lambda x: x[0], filter(lambda x: x[1][4]>thresh_rate, pword)))\n",
    "merge = train[['q1', 'q2']]\n",
    "pword_oside_tags = []\n",
    "for i in merge.index:\n",
    "    tags = []\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    for word in pword_oside:\n",
    "        if (word in q1_words) and (word not in q2_words):\n",
    "            tags.append(1.0)\n",
    "        else:\n",
    "            tags.append(0.0)\n",
    "    pword_oside_tags.append(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算词的双侧影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_least = 300\n",
    "merge = train[['q1', 'q2']]\n",
    "words_power = dict(sorted_words_power)\n",
    "pword_dside_rate = []\n",
    "for i in merge.index:\n",
    "    rate = 1.0\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    share_words = list(q1_words.intersection(q2_words))\n",
    "    for word in share_words:\n",
    "        if word in pword_dside:\n",
    "            rate *= (1.0 - words_power[word][6])\n",
    "    pword_dside_rate.append(1-rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算词的单侧影响力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_least = 300\n",
    "merge = train[['q1', 'q2']]\n",
    "words_power = dict(sorted_words_power)\n",
    "pword_oside_rate = []\n",
    "for i in merge.index:\n",
    "    rate = 1.0\n",
    "    q1_words = set(merge.loc[i, 'q1'].lower().split())\n",
    "    q2_words = set(merge.loc[i, 'q2'].lower().split())\n",
    "    q1_diff = list(set(q1_words).difference(set(q2_words)))\n",
    "    q2_diff = list(set(q2_words).difference(set(q1_words)))\n",
    "    all_diff = set(q1_diff + q2_diff)\n",
    "    for word in all_diff:\n",
    "        if word in pword_oside:\n",
    "            rate *= (1.0-words_power[word][4])\n",
    "    pword_oside_rate.append(1-rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并提取的词特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_common_char_ratio = pd.DataFrame(adjusted_common_word_ratio)\n",
    "pchar_dside_rate = pd.DataFrame(pword_dside_rate)\n",
    "pchar_oside_rate = pd.DataFrame(pword_oside_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('output/test_feature_words.csv', index_col=0)\n",
    "test_features = pd.DataFrame(test_features)\n",
    "test_features = pd.merge(test_features, adjusted_common_char_ratio, left_index = True,right_index =  True)\n",
    "test_features = pd.merge(test_features, pchar_dside_rate, left_index = True,right_index =  True)\n",
    "test_features = pd.merge(test_features, pchar_oside_rate, left_index = True,right_index =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.columns = ['adjusted_common_word_ratio','edit_distance','len_diff',\n",
    "                          'pword_dside_rate','pword_oside_rate','adjusted_common_char_ratio','pchar_dside_rate','pchar_oside_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.to_csv('output/test_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172956, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
